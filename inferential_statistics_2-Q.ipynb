{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential statistics II - Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous frequentist mini-projects, you did frequentist calculations to perform inference from a sample of data. Such inference relies on theory largely developed from the 19th-Century onwards that is subject to certain assumptions or theoretical limits. These are fine if those assumptions hold for the particular case you're working on, and what you want to do has a known theoretical distribution (for example the mean of a sampling distribution that we looked at in the previous mini-project.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this mini-project, you'll use the same medical charge data you used in the frequentist inference mini-project, but this time you'll make inferences about the population using bootstrapping (ie. simulating repeated re-runs of an experiment.) If frequentism is about using assumptions and theoretical results to calculate what we expect to happen were an experiment to be run again and again and again, then bootstrapping is about using computing power to essentially re-run the sample draw again and again and again to see what actually happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these exercises do not strictly depend on these concepts, we encourage you to complete the previous mini-projects before starting this one so that you can approach this assignment with a good understanding of frequentist concepts like:\n",
    "* the _z_-statistic\n",
    "* the _t_-statistic\n",
    "* the difference and relationship between the two\n",
    "* the Central Limit Theorem, its assumptions and consequences\n",
    "* how to estimate the population mean and standard deviation from a sample\n",
    "* the concept of a sampling distribution of a test statistic, particularly for the mean\n",
    "* how to combine these concepts to calculate confidence intervals and p-values\n",
    "* how those confidence intervals and p-values allow you to perform hypothesis (or A/B) tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete mini-project, it's important that you first complete the bootstrap resources listed in this subunit, as they contain valuable information about how to calculate bootstrap replicates of summary statistics. Having an basic understanding of what confidence intervals and p-values are will also be helpful (we touch on them in this mini-project, but please speak to your mentor or conduct individual research if you'd like to learn more.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "import scipy.stats as stats\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical charge data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_charges = pd.read_csv('data/insurance2.csv')\n",
    "charges = med_charges['charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>insuranceclaim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker  region      charges  insuranceclaim\n",
       "0   19    0  27.900         0       1       3  16884.92400               1\n",
       "1   18    1  33.770         1       0       2   1725.55230               1\n",
       "2   28    1  33.000         3       0       2   4449.46200               0\n",
       "3   33    1  22.705         0       0       1  21984.47061               0\n",
       "4   32    1  28.880         0       0       1   3866.85520               1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_charges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous assignment, you used the frequentist approach to estimate the lower limit for the 95% confidence interval on the mean hospital charge. This approach relies on statistical theory that has been developed over the years and is also limited to statistics for which theoretical results on the sampling distribution exist. These results are remarkably useful and applicable much of the time and under a surprisingly wide range of conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having calculated the 95% lower confidence interval using frequentist theory in the previous exercise, you'll now use bootstrap inference to verify your calculations and check that you get consistent results without making the assumptions required before. After all, the distribution of charges really was very non-normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Use bootstrap sampling to estimate the same 95% confidence interval lower limit as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47)\n",
    "N_rep = 10000\n",
    "\n",
    "\n",
    "def bootstrap_replicates_1d(data,func):\n",
    "    '''Draws bootstrap replicates of 1D data'''\n",
    "    bs_sample = np.random.choice(data,len(data))\n",
    "    return func(bs_sample)\n",
    "\n",
    "def draw_bs_reps(data,func,size=1):\n",
    "    '''Draw bootstrap replicates'''\n",
    "    bs_replicate = np.empty(N_rep)\n",
    "    \n",
    "    #Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicate[i] = bootstrap_replicates_1d(data,func)\n",
    "        \n",
    "    return bs_replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13268.292567069491"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_replicates_meancharges=draw_bs_reps(charges,np.mean,size=10000)\n",
    "np.mean(bs_replicates_meancharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12624.86211913, 13918.00929997])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int_bs_meancharges = np.percentile(bs_replicates_meancharges,[2.5,97.5])\n",
    "conf_int_bs_meancharges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed 10000 replicates immediately after setting the random seed to 47, you should get the value 12724 here, which compares very well with the value 12725 obtained using the _t_-distribution confidence interval previously. It is a most pleasant result to see the predictions of classical frequentist theory match with results that are now possible through the number-crunching ability of computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, in the previous mini-projects, we saw that there are two ways of performing a _t_-test from a sample, depending on whether we can assume the groups have equal variance or not. We can actually easily test this using the bootstrap approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Calculate the 95% confidence interval for the difference between the standard deviations of insurance and non-insurance claim charges (insured - non-insured). Calculate the differences over 10000 replicates. Plot the histogram of values and mark the locations of the percentiles. State the null and alternative hypothesis and comment on whether you would retain or reject the null hypothesis in this case and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: There is no difference between the std dev of insured and uninsured patients\n",
    "# Alternative Hypothesis: We have a variation in the std dev between the insured and uninsured patients\n",
    "# 95% confidence interval with alpha to 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7596.256408655178"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = med_charges[med_charges['insuranceclaim']==1]['charges']\n",
    "no_insurance = med_charges[med_charges['insuranceclaim']==0]['charges']\n",
    "\n",
    "diff_stddev_charges = np.std(insurance) - np.std(no_insurance)\n",
    "diff_stddev_charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47)\n",
    "def diff_of_stddev(data1,data2):\n",
    "    diff = np.std(data1) - np.std(data2)\n",
    "    return diff\n",
    "\n",
    "def permutation_sample(data1,data2):\n",
    "    data = np.concatenate((data1,data2))\n",
    "    permuted_data = np.random.permutation(data)\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "    return perm_sample_1 , perm_sample_2\n",
    "    #return perm_sample_1.shape ,perm_sample_2.shape\n",
    "\n",
    "def draw_perm_reps(data1,data2,func,size=1):\n",
    "    perm_replicates = np.empty(size)\n",
    "    for i in range(size):\n",
    "        perm_sample_1 , perm_sample_2 = permutation_sample(data1,data2)\n",
    "        perm_replicates[i] = diff_of_stddev(perm_sample_1,perm_sample_2)\n",
    "    return perm_replicates\n",
    "    return perm_sample_1\n",
    "    return perm_sample_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_diff_of_stddev = diff_of_stddev(insurance,no_insurance)\n",
    "empirical_diff_of_stddev\n",
    "charges_stddev_diff_perm_replicates = draw_perm_reps(insurance,no_insurance,np.std,size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1233.13553099,  1255.16493463])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int_stddev_diff = np.percentile(charges_stddev_diff_perm_replicates,[2.5,97.5])\n",
    "conf_int_stddev_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows that the confidence interval could contain the possibility that difference in std dev is zero. \n",
    "# Hence the null hypothesis is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WorkStation\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(charges_stddev_diff_perm_replicates,bins = 20,normed = False)\n",
    "_ = plt.axvline(conf_int_stddev_diff[0],color='red')\n",
    "_ = plt.axvline(conf_int_stddev_diff[1],color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perm_sample_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-b6d0de005a93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m stats.ttest_ind_from_stats(mean1=np.mean(perm_sample_1), std1=np.std(perm_sample_1), nobs1=len(perm_sample_1),\n\u001b[0m\u001b[0;32m      2\u001b[0m                            mean2=np.mean(perm_sample_2), std2=np.std(perm_sample_2), nobs2=len(perm_sample_2))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perm_sample_1' is not defined"
     ]
    }
   ],
   "source": [
    "stats.ttest_ind_from_stats(mean1=np.mean(perm_sample_1), std1=np.std(perm_sample_1), nobs1=len(perm_sample_1),\n",
    "                           mean2=np.mean(perm_sample_2), std2=np.std(perm_sample_2), nobs2=len(perm_sample_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval and p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval above is often a useful quantity to estimate. If we wish to limit our expected probability of making a Type I error (where we wrongly reject the null hypothesis, and it is, instead, true) to $\\alpha$, the associated confidence interval is our estimate of the interval within which we expect the true population value to be found $100\\times(1 - \\alpha)$% of the time we do this test. In the above we performed bootstrap replicates to estimate the interval and reject the null hypothesis if this interval did not contain zero. You will sometimes see such an interval reported in the output of statistical functions.\n",
    "\n",
    "The partner of the confidence interval is the p-value. The p-value and the confidence interval are linked through our choice of $\\alpha$. The p-value tells us how likely it is, under the null hypothesis, to get an outcome at least as extreme as what was observed. If this fails to reach the level of our _pre-specified_ $\\alpha$, we decide the null hypothesis is sufficiently unlikely to be true and thus reject it. To calculate this p-value via the bootstrap, we have to put ourselves in a position where we are simulating the null hypothesis being true and then calculate the fraction of times we observe a result at least as extreme as that actually observed.\n",
    "\n",
    "Remember how, previously, you used the _t_-test to calculate the p-value for the observed difference between the means of insured and non-insured medical cases. We're now going to repeat this, this time using the bootstrap approach.\n",
    "\n",
    "__Q:__ Perform a bootstrapped hypothesis test at the 5% significance level ($\\alpha = 0.05$) to calculate the p-value of the observed difference between insurance and non-insurance charges, state your null and alternative hypotheses and whether you retain or reject the null hypothesis for the given significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47)\n",
    "\n",
    "def diff_of_means(data1,data2):\n",
    "    diff = np.mean(data1) - np.mean(data2)\n",
    "    return diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7602.506384231368"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_diff_of_means = diff_of_means(insurance,no_insurance)\n",
    "empirical_diff_of_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-254.5880581 ,  -26.03721692, -485.38333355, ..., -560.54822213,\n",
       "         57.06654918, -935.84569063])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_perm_reps_mean_diff(insurance,no_insurance,diff_of_means,size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_meandiff = np.sum(charges_mean_diff_perm_replicates >= empirical_diff_of_means) / len(charges_mean_diff_perm_replicates)\n",
    "\n",
    "p_value_meandiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ To put the above result in perspective, plot the histogram of your bootstrapped differences along with lines marking the locations of the observed difference. (Why would we plot more than one line, given that we only have one observed difference?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Compare your p-value above with that obtained using the _t_-test function in the previous assignment. Do you think you would want to try to perform enough bootstrap replicates to observe a random difference as large as that we did observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ Consider the two variants of the _t_-test we performed in the previous assignment. Which one would you use now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q:__ If, instead of being asked whether the means of two groups were different, you were working with an ad-recommender team who wanted to release a new recommendation algorithm, and you were looking at click-through rate both for the current algorithm (call it A) and from trials of their new algorithm (call it B), would you perform a two-sided test as above? What would be your null and alternative hypotheses and what would be the real-world consequence of rejecting the null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning outcomes\n",
    "\n",
    "You've previously applied frequentist methods to calculate confidence intervals, p-values, and perform hypothesis tests. Frequentist methods use theoretical results to calculate what we expect would happen if experiments were to be run again and again and again. Now you've seen how you can do the same things using the bootstrap approach, which does not rely on such theory, and attendant assumptions, but instead literally does run experiments again and again and again.\n",
    "\n",
    "In these exercises, you have:\n",
    "* calculated the same confidence interval lower limit as you did previously\n",
    "* tested the assumption that the variances of the two groups (insured vs. non-insured) were equal - something a bit harder to do using the frequentist method because of the nature of the sampling distribution for variance\n",
    "* calculated the p-value for the difference between the means of the two groups and compared with the result obtained using the previous frequentist approach\n",
    "\n",
    "You are now well equipped to apply the bootstrap approach to a wide variety of problems. Just think about what conditions you wish to recreate in your simulated reruns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
